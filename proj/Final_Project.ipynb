{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project\n",
    "### Xi Yang 16216573\n",
    "\n",
    "### data\n",
    "** the data set are from i2b2 which needs auth to public, so I could not shared the data, but example data are described below **\n",
    "- training data: C:\\Users\\xiyang\\Google Drive\\NLP_Project\\i2b2_data\\concept_assertion_relation_training_data\n",
    "    1. concept: beth/concept/*.con; partners/concept/*.con\n",
    "    2. txt: beth/txt/*.txt; partners/txt/*.txt\n",
    "- testing data: C:\\Users\\xiyang\\Google Drive\\NLP_Project\\i2b2_data\\reference_standard_for_test_data\n",
    "    1. concept: concepts/*.con\n",
    "    2. txt: test_data/*.txt\n",
    "\n",
    "### data sample\n",
    "** .con and .txt files are linked by sharing same filename **\n",
    "- data in .con file: c=\"angap\" 65:25 65:25||t=\"test\"\n",
    "- data in .txt file: 2018-10-31 06:25 AM BLOOD Glucose - 91 UreaN - 19 Creat - 0.8 Na - 134 K - 4.0 Cl - 98 HCO3 - 26 _AnGap_ - 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in training and testing data as raw\n",
    "import glob\n",
    "from functools import reduce\n",
    "base_path = \"C:\\\\Users\\\\xiyang\\\\Google Drive\\\\NLP_Project\\\\i2b2_data\\\\concept_assertion_relation_training_data\"\n",
    "\n",
    "con_file_paths = [base_path + \"\\\\beth\\\\concept\\\\*.con\", base_path + \"\\\\partners\\\\concept\\\\*.con\"]\n",
    "txt_file_paths = [base_path + \"\\\\beth\\\\txt\\\\*.txt\", base_path + \"\\\\parterns\\\\txt\\\\*.txt\"]\n",
    "\n",
    "con_files = list(reduce(lambda y, z: y + z, list(map(lambda x: glob.glob(x),  [files for files in con_file_paths]))))\n",
    "txt_files = list(reduce(lambda y, z: y + z, list(map(lambda x: glob.glob(x),  [files for files in txt_file_paths]))))\n",
    "\n",
    "#in each file pair, the first is the txt and second is the associated concept file\n",
    "file_pairs = list(zip(txt_files, con_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In txt file, each line is a sentence token and each word need to be tokenized\n",
    "tokenize line into words listed in each line and pedding related tags based on information from con file\n",
    "Example:\n",
    "    concept: c=\"angap\" 65:25 65:25||t=\"test\"\n",
    "    sentence: 98 HCO3 - 26 AnGap - 14\n",
    "    output:\n",
    "    98    o\n",
    "    HCO3    o\n",
    "    -    o\n",
    "    26    o\n",
    "    ANGap    B-test\n",
    "    -    o\n",
    "    14   o\n",
    "'''\n",
    "import re\n",
    "\n",
    "def preprocess_raw_txt_file(file_pair):\n",
    "    con_dict = dict()\n",
    "    txt = file_pair[0]\n",
    "    con = file_pair[1]\n",
    "    \n",
    "    with open(con, \"r\") as fr:\n",
    "        for i, line in enumerate(fr):\n",
    "            info1 = line.split(\"||\")\n",
    "            info2 = info1[0].split(\" \")\n",
    "            c = re.findall(r'\\\"(.+?)\\\"', info2[0])[0]\n",
    "            line_num = info2[1].split(\":\")[0]\n",
    "            line_num_check = info2[2].split(\":\")[0]\n",
    "            if int(line_num_check) - int(line_num) != 0:\n",
    "                continue\n",
    "            b_tag_pos = \n",
    "            \n",
    "            \n",
    "    with open(txt, \"r\") as fr:\n",
    "        for line_index, line in enumerate(fr):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
